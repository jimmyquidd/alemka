[
  {
    "path": "posts/2022-10-31-yem/",
    "title": "Yapısal Eşitlik Modellemesi - structural equation modelling",
    "description": "YEM: 'Your View on Science' ölçeğinden elde edilen 2015 PISA Turkiye örneklemi ile bir örnek çalışma. \nBu çalışma Gazi üniversitesi'nde 'Yapısal Eşitlik Modellemeleri' dersi kapsamında rapor olarak hazırlanmıştır.",
    "author": [
      {
        "name": "Ali Emre Karagül",
        "url": "https://www.linkedin.com/in/ali-emre-karag%C3%BCl/"
      }
    ],
    "date": "2022-10-30",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nPre-processing süreci\r\nAnaliz Süreci\r\nDoğrulayıcı Faktör Analizi (DFA)\r\nBI-FACTOR MODELLER\r\nEN UYUMLU MODEL:DWLS çıktıları\r\nModel uyum indeksleri\r\nFaktör Kovaryansları\r\nArtık (residual) Varyanslar\r\nModel gösterimi\r\n\r\n\r\n\r\nBu çalışmada PISA 2015 “student questionnaire: paper based verison” içerisindeki en son alt ölçek olan ‘Your View on Science’ ölçeğinden elde edilen veriler kullanılmıştır. Türkiye örnekleminden faydalanılmıştır. Bu örneklem ile bahsi geçen ölçeğin yapısal eşitlik modelleri oluşturulmuş ve karşılaştırılmıştır. Adım adım veri setinin R ile analize hazır hale getirilmesi anlatılmaktadır. Doğrudan analiz ile ilgileniyorsanız aşağıda ‘Analiz Süreci’ başlığına ilerleyiniz.\r\nPre-processing süreci\r\nÖncelikle OECD tarafından yayınlanan veri setini şuradan indiriyoruz. İndirilen bu dosya .sav uzantılı bbir dosya. Bu tür dosyaları açmak için haven paketi read_sav fonksiyonundan faydalanabiliriz. Veri setinin tamamına ihtiyacımız yok, zaten oldukça büyük bir veri. Ülke değilşkeni ve ilgili ölçeğin maddeleri yeterli olacaktır. İndirdiğimiz .sav uzantılı dosyayı working directory’mize taşıdıktan sonra çalıştıracağımız kod satırı şunlar:\r\n\r\n\r\nShow code\r\n\r\nlibrary(haven) \r\ndata <- na.omit(read_sav(\r\n  \"CY6_MS_CMB_STU_QQQ.sav\",\r\n  col_select = c(\r\n    \"CNT\",\r\n    \"ST092Q01TA\",\r\n    \"ST092Q02TA\",\r\n    \"ST092Q04TA\",\r\n    \"ST092Q05TA\",\r\n    \"ST092Q06NA\",\r\n    \"ST092Q08NA\",\r\n    \"ST092Q09NA\",\r\n    \r\n    \"ST094Q01NA\",\r\n    \"ST094Q02NA\",\r\n    \"ST094Q03NA\",\r\n    \"ST094Q04NA\",\r\n    \"ST094Q05NA\",\r\n    \r\n    \"ST113Q01TA\",\r\n    \"ST113Q02TA\",\r\n    \"ST113Q03TA\",\r\n    \"ST113Q04TA\",\r\n    \r\n    \"ST129Q01TA\",\r\n    \"ST129Q02TA\",\r\n    \"ST129Q03TA\",\r\n    \"ST129Q04TA\",\r\n    \"ST129Q05TA\",\r\n    \"ST129Q06TA\",\r\n    \"ST129Q07TA\",\r\n    \"ST129Q08TA\",\r\n    \r\n    \"ST131Q01NA\",\r\n    \"ST131Q03NA\",\r\n    \"ST131Q04NA\",\r\n    \"ST131Q06NA\",\r\n    \"ST131Q08NA\",\r\n    \"ST131Q11NA\"\r\n  )\r\n))\r\n\r\n\r\nÜlke değişkenine artık ihtiyacımız yok. O nedenle veri setimizi sadece ölçek maddelerini içerecek şekilde yeniden tanımlayalım:\r\n\r\n\r\nShow code\r\n\r\nlibrary(dplyr)\r\nscience_data<-filter(data, CNT==\"TUR\")[,-1]\r\n\r\n\r\nBu veri setini şu kod satırını yürüterek .csv uzantılı bir dosya olarak bilgisayarıma kaydediyorum. Böylece analiz aşamasında o halini de paylaşabileceğim:\r\n\r\n\r\nShow code\r\n\r\nwrite.csv(science_data, \"science_data.csv\", row.names = FALSE)\r\n\r\n\r\nAnaliz Süreci\r\nİlgili ölçekten elde edilen veriyi .csv uzantılı dosya olarak indirebilirsiniz. Bunu read.csv fonksiyonu ile R ortamına aktarabilirsiniz. Veri setimiz hazır. Analizimizde öncelikle doğrulayı faktör analizi kullanacağız. Daha sonra da bi-faktör modelleme yapacağız. Veri setimizi tekrar yükleyelim:\r\n\r\n\r\n\r\nDoğrulayıcı Faktör Analizi (DFA)\r\nÇalışmamıza konu olan ölçek beş faktörden oluşmaktadır. Bu yapı ile ölçek geliştirme sürecinde tanımlanmıştır. Her faktörde farklı sayılarda maddeler yer almaktadır. Veri setinde bunlar ST ön eki ve faktör numarası ile tanımlanmıştır. Faktörleri ve veri setindeki kodlamalarını şu şekilde listeleyelim:\r\nST092: How informed are you about the following environmental issues?\r\nST094: How much do you disagree or agree with the statements about yourself below?\r\nST113: How much do you agree with the statements below?\r\nST129: How easy do you think it would be for you to perform the following tasks on your own?\r\nST131: How much do you disagree or agree with the statements below?\r\nBu beş faktörün altında tanımlanan yapıya göre DFA uygulayacağız ve bir geçerlilik çalışması yürüteceğiz. Bunun için öncelikle modelimizi R’a tanıtalım:\r\n\r\n\r\nShow code\r\n\r\nScience.model <- 'ST092 =~ 1* ST092Q01TA+\r\n                              ST092Q02TA+\r\n                              ST092Q04TA+\r\n                              ST092Q05TA+\r\n                              ST092Q06NA+\r\n                              ST092Q08NA+\r\n                              ST092Q09NA\r\n                              \r\n                  ST094 =~ 1* ST094Q01NA+\r\n                              ST094Q02NA+\r\n                              ST094Q03NA+\r\n                              ST094Q04NA+\r\n                              ST094Q05NA\r\n                              \r\n                  ST113 =~ 1* ST113Q01TA+\r\n                              ST113Q02TA+\r\n                              ST113Q03TA+\r\n                              ST113Q04TA\r\n                  \r\n                  ST129 =~ 1* ST129Q01TA+\r\n                              ST129Q02TA+\r\n                              ST129Q03TA+\r\n                              ST129Q04TA+\r\n                              ST129Q05TA+\r\n                              ST129Q06TA+\r\n                              ST129Q07TA+\r\n                              ST129Q08TA\r\n                              \r\n                  ST131 =~ 1* ST131Q01NA+\r\n                              ST131Q03NA+\r\n                              ST131Q04NA+\r\n                              ST131Q06NA+\r\n                              ST131Q08NA+\r\n                              ST131Q11NA            \r\n                    \r\n                           \r\n                            ST092 ~~ ST094\r\n                            ST092 ~~ ST113\r\n                            ST092 ~~ ST129\r\n                            ST092 ~~ ST131\r\n                            \r\n                            ST094 ~~ ST113\r\n                            ST094 ~~ ST129\r\n                            ST094 ~~ ST131\r\n                            \r\n                            ST113 ~~ ST129\r\n                            ST113 ~~ ST131\r\n                            \r\n                            ST129 ~~ ST131'\r\n\r\n\r\nŞimdi Türkiye örnekleminden elde edilen verimizin bu modele uyum sağlayıp sağlamadığına bakacağız. Bu aşamada çeşitli modelleme yaklaşımlarından çıktılar alarak bunları karşılaştıracağız. Bu modelleme yaklaşımları şunlardır:\r\nmaximum likelihood model (MLM)\r\nweighted least squares (WLS)\r\nrobust maximum likelihood model (RMLM)\r\ndiagonally weighted least squares (DWLS)\r\nYukarıdaki lsitede görüldüğü sıra ile modellerimizi lavaan paketiyle oluşturalım:\r\n\r\n\r\nShow code\r\n\r\nlibrary(lavaan)\r\nmodel_mlm <- cfa(Science.model, data = science_data)\r\nmodel_wls <- cfa(Science.model, WLS.V = TRUE, data = science_data)\r\nmodel_rml <- cfa(Science.model, estimator = \"MLM\", se = \"robust.mlm\", data = science_data)\r\nmodel_dwls<-cfa(Science.model, data = science_data, estimator=\"DWLS\")\r\n\r\n\r\nHer biri için de ayrı ayrı analiz çıktılarını summary() fonksiyonu ile tanımlayalım:\r\n\r\n\r\nShow code\r\n\r\nscience.mlm<-summary(\r\n  model_mlm,\r\n  fit.measures = TRUE,\r\n  standardized = TRUE,\r\n  rsquare = TRUE,\r\n  modindices = TRUE\r\n)\r\nscience.wls<-summary(\r\n  model_wls,\r\n  fit.measures = TRUE,\r\n  standardized = TRUE,\r\n  rsquare = TRUE,\r\n  modindices = TRUE\r\n)\r\nscience.rml<-summary(\r\n  model_rml,\r\n  fit.measures = TRUE,\r\n  standardized = TRUE,\r\n  rsquare = TRUE,\r\n  modindices = TRUE\r\n)\r\nscience.dwls<-summary(\r\n  model_dwls,\r\n  fit.measures = TRUE,\r\n  standardized = TRUE,\r\n  rsquare = TRUE,\r\n  modindices = TRUE\r\n)\r\n\r\n\r\nTabi ki hem literatürde en yaygın kullanılan hem de alan uzmanları tarafından en ok önerilen yöntem olması sebebiyle MLM yöntemi önceliğimiz. Bu yöntemde normallik varsayımı karşılandığı sürece güçlü analizler elde edilebilmektedir. Veri setimiz de büyük bir örneklemden elde edildiği için bu varsayımın karşılandığı düşünülmektedir. Grafik incelemelerinde de bu durum görülecektir. Dolayısıyla öncelikle MLM’ye ait uyum indekslerini görelim:\r\n\r\n\r\nShow code\r\n\r\nscience.mlm[[\"fit\"]]\r\n\r\n\r\n\r\n             npar              fmin             chisq \r\n           70.000             0.652          6055.193 \r\n               df            pvalue    baseline.chisq \r\n          395.000             0.000         96221.017 \r\n      baseline.df   baseline.pvalue               cfi \r\n          435.000             0.000             0.941 \r\n              tli              logl unrestricted.logl \r\n            0.935       -135531.110       -132503.514 \r\n              aic               bic            ntotal \r\n       271202.220        271653.284          4646.000 \r\n             bic2             rmsea    rmsea.ci.lower \r\n       271430.850             0.056             0.054 \r\n   rmsea.ci.upper      rmsea.pvalue              srmr \r\n            0.057             0.000             0.039 \r\n\r\nBu çıktılar incelendiğinde, 70 parametreli 395 serbestlik derecesinde bir model oluştuğu görülmektedir. CFI ve TLI uyum indekleri .90 eşik değerin üzerindeyken, RMSEA ve SRMR .06’nın altında yer almaktadır. Bu durumda modelimizin uyumlu olduğu düşünülebilir. Yine de diğer modeller ile de karşılaştırmak gerekir. Onların uyum indeklerini de görelim:\r\nWLS model:\r\n\r\n\r\nShow code\r\n\r\nscience.wls[[\"fit\"]]\r\n\r\n\r\n\r\n             npar              fmin             chisq \r\n           70.000             0.652          6055.193 \r\n               df            pvalue    baseline.chisq \r\n          395.000             0.000         96221.017 \r\n      baseline.df   baseline.pvalue               cfi \r\n          435.000             0.000             0.941 \r\n              tli              logl unrestricted.logl \r\n            0.935       -135531.110       -132503.514 \r\n              aic               bic            ntotal \r\n       271202.220        271653.284          4646.000 \r\n             bic2             rmsea    rmsea.ci.lower \r\n       271430.850             0.056             0.054 \r\n   rmsea.ci.upper      rmsea.pvalue              srmr \r\n            0.057             0.000             0.039 \r\n\r\nRML model:\r\n\r\n\r\nShow code\r\n\r\nscience.rml[[\"fit\"]]\r\n\r\n\r\n\r\n                         npar                          fmin \r\n                       70.000                         0.652 \r\n                        chisq                            df \r\n                     6055.193                       395.000 \r\n                       pvalue                  chisq.scaled \r\n                        0.000                      4484.352 \r\n                    df.scaled                 pvalue.scaled \r\n                      395.000                         0.000 \r\n         chisq.scaling.factor                baseline.chisq \r\n                        1.350                     96221.017 \r\n                  baseline.df               baseline.pvalue \r\n                      435.000                         0.000 \r\n        baseline.chisq.scaled            baseline.df.scaled \r\n                    75815.224                       435.000 \r\n       baseline.pvalue.scaled baseline.chisq.scaling.factor \r\n                        0.000                         1.269 \r\n                          cfi                           tli \r\n                        0.941                         0.935 \r\n                   cfi.scaled                    tli.scaled \r\n                        0.946                         0.940 \r\n                   cfi.robust                    tli.robust \r\n                        0.942                         0.936 \r\n                         logl             unrestricted.logl \r\n                  -135531.110                   -132503.514 \r\n                          aic                           bic \r\n                   271202.220                    271653.284 \r\n                       ntotal                          bic2 \r\n                     4646.000                    271430.850 \r\n                        rmsea                rmsea.ci.lower \r\n                        0.056                         0.054 \r\n               rmsea.ci.upper                  rmsea.pvalue \r\n                        0.057                         0.000 \r\n                 rmsea.scaled         rmsea.ci.lower.scaled \r\n                        0.047                         0.046 \r\n        rmsea.ci.upper.scaled           rmsea.pvalue.scaled \r\n                        0.048                         1.000 \r\n                 rmsea.robust         rmsea.ci.lower.robust \r\n                        0.055                         0.053 \r\n        rmsea.ci.upper.robust           rmsea.pvalue.robust \r\n                        0.056                            NA \r\n                         srmr \r\n                        0.039 \r\n\r\nDWLS model:\r\n\r\n\r\nShow code\r\n\r\nscience.dwls[[\"fit\"]]\r\n\r\n\r\n\r\n           npar            fmin           chisq              df \r\n         70.000           0.188        1744.348         395.000 \r\n         pvalue  baseline.chisq     baseline.df baseline.pvalue \r\n          0.000      120867.135         435.000           0.000 \r\n            cfi             tli           rmsea  rmsea.ci.lower \r\n          0.989           0.988           0.027           0.026 \r\n rmsea.ci.upper    rmsea.pvalue            srmr \r\n          0.028           1.000           0.034 \r\n\r\nTüm bu çıktılar incelendiğinde, en uygun modelin diagonally weighted least squares (DWLS) olduğu düşünülmektedir. Veri setinin farklı ölçek düzeyinde olması ve kategorik olması bu durumun sebebi olabilir. DWLS modeli, liteatürde yaygın bir şekilde bu tür veri setleri için önerilmektedir.\r\nBI-FACTOR MODELLER\r\nBi faktör modellemede yapıyı oluşturan faktörlerin tüm maddelerden oluşan genel faktör ile ilişkisi incelenerek karar verilir. Bu amaçla DFA örneğinde olduğu gibi model tanımlamamızı yapıyoruz:\r\n\r\n\r\nShow code\r\n\r\nScience.bifactormodel <- 'general.factor =~\r\n                              ST092Q01TA+\r\n                              ST092Q02TA+\r\n                              ST092Q04TA+\r\n                              ST092Q05TA+\r\n                              ST092Q06NA+\r\n                              ST092Q08NA+\r\n                              ST092Q09NA+\r\n                              ST094Q01NA+\r\n                              ST094Q02NA+\r\n                              ST094Q03NA+\r\n                              ST094Q04NA+\r\n                              ST094Q05NA+\r\n                              ST113Q01TA+\r\n                              ST113Q02TA+\r\n                              ST113Q03TA+\r\n                              ST113Q04TA+\r\n                              ST129Q01TA+\r\n                              ST129Q02TA+\r\n                              ST129Q03TA+\r\n                              ST129Q04TA+\r\n                              ST129Q05TA+\r\n                              ST129Q06TA+\r\n                              ST129Q07TA+\r\n                              ST129Q08TA+\r\n                              ST131Q01NA+\r\n                              ST131Q03NA+\r\n                              ST131Q04NA+\r\n                              ST131Q06NA+\r\n                              ST131Q08NA+\r\n                              ST131Q11NA\r\n\r\n                  ST092 =~ 1* ST092Q01TA+\r\n                              ST092Q02TA+\r\n                              ST092Q04TA+\r\n                              ST092Q05TA+\r\n                              ST092Q06NA+\r\n                              ST092Q08NA+\r\n                              ST092Q09NA\r\n\r\n                  ST094 =~ 1* ST094Q01NA+\r\n                              ST094Q02NA+\r\n                              ST094Q03NA+\r\n                              ST094Q04NA+\r\n                              ST094Q05NA\r\n\r\n                  ST113 =~ 1* ST113Q01TA+\r\n                              ST113Q02TA+\r\n                              ST113Q03TA+\r\n                              ST113Q04TA\r\n\r\n                  ST129 =~ 1* ST129Q01TA+\r\n                              ST129Q02TA+\r\n                              ST129Q03TA+\r\n                              ST129Q04TA+\r\n                              ST129Q05TA+\r\n                              ST129Q06TA+\r\n                              ST129Q07TA+\r\n                              ST129Q08TA\r\n\r\n                  ST131 =~ 1* ST131Q01NA+\r\n                              ST131Q03NA+\r\n                              ST131Q04NA+\r\n                              ST131Q06NA+\r\n                              ST131Q08NA+\r\n                              ST131Q11NA\r\n                              \r\n\r\n                general.factor  ~~ 0*ST092\r\n                general.factor  ~~ 0*ST094\r\n                general.factor  ~~ 0*ST113\r\n                general.factor  ~~ 0*ST129\r\n                general.factor  ~~ 0*ST131\r\n                \r\n                            ST092 ~~ ST094\r\n                            ST092 ~~ ST113\r\n                            ST092 ~~ ST129\r\n                            ST092 ~~ ST131\r\n\r\n                            ST094 ~~ ST113\r\n                            ST094 ~~ ST129\r\n                            ST094 ~~ ST131\r\n\r\n                            ST113 ~~ ST129\r\n                            ST113 ~~ ST131\r\n\r\n                            ST129 ~~ ST131'\r\n\r\n\r\nArdından modellerimizi veri setimiz ile sınıyoruz.\r\n\r\n\r\nShow code\r\n\r\nScience.bifactormodel_mlm <-\r\n  cfa(\r\n    Science.bifactormodel,\r\n    data = science_data,\r\n    std.lv = TRUE,\r\n    information = \"observed\"\r\n  )\r\nScience.bifactormodel_rml <-\r\n  cfa(\r\n    Science.bifactormodel,\r\n    data = science_data,\r\n    estimator = \"MLM\",\r\n    se = \"robust.mlm\",\r\n    std.lv = TRUE,\r\n    information = \"observed\"\r\n  )\r\nbifactor_mlm <- summary(Science.bifactormodel_mlm ,\r\n        fit.measures = TRUE,\r\n        standardized = TRUE)\r\nbifactor_rml <- summary(Science.bifactormodel_rml ,\r\n        fit.measures = TRUE,\r\n        standardized = TRUE)\r\n\r\nbifactor_mlm[['fit']]\r\nbifactor_rml[['fit']]\r\n\r\n\r\nBI-FAKTÖR ML model:\r\n\r\n             npar              fmin             chisq \r\n           95.000             0.634          5891.081 \r\n               df            pvalue    baseline.chisq \r\n          370.000             0.000         96221.017 \r\n      baseline.df   baseline.pvalue               cfi \r\n          435.000             0.000             0.942 \r\n              tli              logl unrestricted.logl \r\n            0.932       -135449.054       -132503.514 \r\n              aic               bic            ntotal \r\n       271088.109        271700.266          4646.000 \r\n             bic2             rmsea    rmsea.ci.lower \r\n       271398.392             0.057             0.055 \r\n   rmsea.ci.upper      rmsea.pvalue              srmr \r\n            0.058             0.000             0.328 \r\n\r\nBI-FAKTÖR ROBUST ML model:\r\n\r\n                         npar                          fmin \r\n                       95.000                         0.634 \r\n                        chisq                            df \r\n                     5891.081                       370.000 \r\n                       pvalue                  chisq.scaled \r\n                        0.000                      4166.363 \r\n                    df.scaled                 pvalue.scaled \r\n                      370.000                         0.000 \r\n         chisq.scaling.factor                baseline.chisq \r\n                        1.414                     96221.017 \r\n                  baseline.df               baseline.pvalue \r\n                      435.000                         0.000 \r\n        baseline.chisq.scaled            baseline.df.scaled \r\n                    19393.334                       435.000 \r\n       baseline.pvalue.scaled baseline.chisq.scaling.factor \r\n                        0.000                         4.962 \r\n                          cfi                           tli \r\n                        0.942                         0.932 \r\n                   cfi.scaled                    tli.scaled \r\n                        0.800                         0.765 \r\n                   cfi.robust                    tli.robust \r\n                        0.943                         0.933 \r\n                         logl             unrestricted.logl \r\n                  -135449.054                   -132503.514 \r\n                          aic                           bic \r\n                   271088.109                    271700.266 \r\n                       ntotal                          bic2 \r\n                     4646.000                    271398.392 \r\n                        rmsea                rmsea.ci.lower \r\n                        0.057                         0.055 \r\n               rmsea.ci.upper                  rmsea.pvalue \r\n                        0.058                         0.000 \r\n                 rmsea.scaled         rmsea.ci.lower.scaled \r\n                        0.047                         0.046 \r\n        rmsea.ci.upper.scaled           rmsea.pvalue.scaled \r\n                        0.048                         1.000 \r\n                 rmsea.robust         rmsea.ci.lower.robust \r\n                        0.056                         0.054 \r\n        rmsea.ci.upper.robust           rmsea.pvalue.robust \r\n                        0.057                            NA \r\n                         srmr \r\n                        0.328 \r\n\r\nBu çıktılar incelendiğinde de bi faktör modelin verimize DWLS model kadar uyumlu olmadığı görülmektedir. Bu nedenle DWLS modelin en uyumlu model olduğu düşünülmektedir. Bu modelin çıktılarını tablolaştıralım.\r\nEN UYUMLU MODEL:DWLS çıktıları\r\nNOT: Faktör varyansları sabitlenerek model oluşturulduğu için faktör varyansları tablosu raporlaştırılmamıştır.\r\nModel uyum indeksleri\r\n\r\nParametre Tahminleri\r\n\r\nFaktör Kovaryansları\r\n\r\nArtık (residual) Varyanslar\r\n\r\nModel gösterimi\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-10-31-yem/images/paste-A04B6DB6.png",
    "last_modified": "2022-11-07T02:59:27+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-10-31-test-eitleme/",
    "title": "Test Equating",
    "description": "Equating two test forms: \nThis is a simple test equating study. The data used in this study is simulated from real data. We don't use the real data for privacy purposes here.",
    "author": [
      {
        "name": "Ali Emre Karagül",
        "url": "https://www.linkedin.com/in/ali-emre-karag%C3%BCl/"
      }
    ],
    "date": "2022-09-20",
    "categories": [],
    "contents": "\r\nThis is a simple test equating study. The data used in this study is simulated from real data. We don’t use the real data for privacy purposes here.\r\n2020-2021 Fall Term A Level’s first quiz has 40 items. 2022-2023 Fall Term A Level’s first quiz has 40 items. 35 of the items in each test forms are unique items while 5 of them are common, thus will be called as “anchor items” in this study. For the readers interest, the items belong to four main domains (listening, structure, vocabbulary and reading), yet the common items are only in the reading section. This is obviously a violation of assumptions of test equating. Still, this study is conveyed for demonstration purposes. Therefore, let’s continue:\r\nTo ensure statistical equation of these two forms, we first introduced the data in R Studio and the first five rows can be seen below:\r\n\r\n\r\nShow code\r\n\r\nQ1 <- read.csv(\"kitap1.csv\", header = TRUE)\r\nhead(Q1)\r\n\r\n  L1 L2 L3 L4 L5 L6 L7 L8 L9 L10 S1 S2 S3 S4 S5 S6 S7 S8 S9 S10 V1 V2\r\n1  0  1  0  1  1  1  0  1  1   0  1  1  0  1  0  0  0  0  0   1  0  1\r\n2  1  1  1  1  1  1  1  1  1   1  0  1  1  0  1  1  0  0  0   0  1  1\r\n3  1  1  1  1  1  1  0  1  1   0  1  1  0  1  1  0  0  1  1   0  0  1\r\n4  1  1  1  1  1  1  1  0  1   0  1  1  0  1  1  0  1  1  0   0  0  1\r\n5  1  1  1  1  1  1  1  0  1   1  1  1  1  1  0  1  0  1  0   0  1  1\r\n6  1  1  1  1  0  0  1  1  1   1  0  0  0  0  0  1  1  1  1   1  1  1\r\n  V3 V4 V5 V6 V7 V8 V9 V10 R1 R2 R3 R4 R5 R6 R7 R8 R9 R10 form\r\n1  1  0  1  0  1  1  1   1  1  1  0  1  1  1  1  1  1   1    x\r\n2  1  1  0  0  1  1  0   0  1  0  1  1  0  1  1  0  1   1    x\r\n3  0  1  0  1  0  1  1   1  1  0  0  1  1  1  0  1  1   1    x\r\n4  1  0  1  1  1  1  0   1  1  1  1  1  0  1  0  0  1   1    x\r\n5  1  0  0  1  1  1  0   1  1  1  1  0  1  1  1  0  1   1    x\r\n6  1  0  0  1  1  1  1   1  1  1  1  1  1  1  1  1  1   1    x\r\n\r\nLater, we introduced the unique and anchor items separately. First 35 items are unique items, and the last 5 items are anchor items.\r\n\r\n\r\nShow code\r\n\r\n# Calculate total scores based on unique items\r\nQ1$total <- rowSums(Q1[, 1:35])\r\n\r\n# Calculate scores based on anchor items\r\nQ1$anchor <- rowSums(Q1[, 36:40])\r\n\r\n\r\nAs we will use the equate package, the data should be contained as frequency tables: Form x (20-21 fall) had a sample of 200 while form y (22-23 fall) had a sample of 133 students. They are defined as:\r\n\r\n\r\nShow code\r\n\r\n#first introduce the equate package:\r\nlibrary(equate)\r\n# Create frequency tables (total score range: 0-35; anchor score range: 0-5)\r\nQ1_x <- freqtab(Q1[1:200, c(\"total\", \"anchor\")], scales = list(0:35, 0:5))\r\nQ1_y <- freqtab(Q1[201:334, c(\"total\", \"anchor\")], scales = list(0:35, 0:5))\r\n\r\n\r\nTo consideration of the reader one more time, we must state that these forms are the first quizzes of the students. They usually get high marks. For instance, you can see below that the students’ scores are distributed left-skewed in both forms. Their total correct answers are distributed between 20 and 35 for the unique items , and between 3 and 5 for anchor items in form X. The situation isn’t different for form y.\r\n\r\n\r\nShow code\r\n\r\n#distrubution of the data among forms and unique/common items\r\nplot(Q1_x, xlab = \"Total Scores Form X\", ylab = \"Common Anchor Scores Form X\")\r\n\r\n\r\nShow code\r\n\r\nplot(Q1_y, xlab = \"Total Scores Form y\", ylab = \"Common Anchor Scores Form y\")\r\n\r\n\r\n\r\nStill, let’s continue… with the smoothing procedure. For both forms, we utilized loglinear presmoothing. Of course there are several other methods, yet literature shows not much a big difference between them, thus not much care given to this issue. again as this is a study with demonstration purposes. After the smoothing, it can be realized that the distribution is highly eye-pleasing right now. Also it is much easier to match the scores even if there isn’t an equivalent of it in the other form.\r\n\r\n\r\nShow code\r\n\r\n#PRESMOOTHING\r\nsmooth_x <- presmoothing(Q1_x, smoothmethod = \"loglinear\")\r\nsmooth_y <- presmoothing(Q1_y, smoothmethod = \"loglinear\")\r\nplot(smooth_x, xlab = \"Total Scores Form X\", ylab = \"Common Anchor Scores Form X\")\r\n\r\n\r\nShow code\r\n\r\nplot(smooth_y, xlab = \"Total Scores Form y\", ylab = \"Common Anchor Scores Form y\")\r\n\r\n\r\n\r\nNow, it can be roughly said that the forms are ready to be equated. Before we try several methods, lets see the results of the Tucker method as it can produce equating error as well:\r\n\r\n\r\nShow code\r\n\r\n## Linear Tucker Equating\r\nQ1_tucker <- equate(Q1_x, Q1_y, type = \"linear\", method = \"tucker\")\r\nQ1_tucker$concordance\r\n\r\n   scale        yx      se.n      se.g\r\n1      0  6.597617 2.0378528 3.3547355\r\n2      1  7.404998 1.9751403 3.2551073\r\n3      2  8.212379 1.9124541 3.1554875\r\n4      3  9.019759 1.8497970 3.0558770\r\n5      4  9.827140 1.7871721 2.9562768\r\n6      5 10.634520 1.7245827 2.8566879\r\n7      6 11.441901 1.6620331 2.7571116\r\n8      7 12.249282 1.5995277 2.6575492\r\n9      8 13.056662 1.5370720 2.5580024\r\n10     9 13.864043 1.4746724 2.4584730\r\n11    10 14.671423 1.4123363 2.3589634\r\n12    11 15.478804 1.3500723 2.2594761\r\n13    12 16.286185 1.2878911 2.1600141\r\n14    13 17.093565 1.2258052 2.0605812\r\n15    14 17.900946 1.1638299 1.9611818\r\n16    15 18.708326 1.1019838 1.8618212\r\n17    16 19.515707 1.0402899 1.7625060\r\n18    17 20.323088 0.9787772 1.6632444\r\n19    18 21.130468 0.9174818 1.5640464\r\n20    19 21.937849 0.8564507 1.4649252\r\n21    20 22.745229 0.7957445 1.3658973\r\n22    21 23.552610 0.7354438 1.2669847\r\n23    22 24.359991 0.6756570 1.1682166\r\n24    23 25.167371 0.6165338 1.0696330\r\n25    24 25.974752 0.5582849 0.9712903\r\n26    25 26.782132 0.5012154 0.8732696\r\n27    26 27.589513 0.4457784 0.7756933\r\n28    27 28.396894 0.3926659 0.6787528\r\n29    28 29.204274 0.3429596 0.5827655\r\n30    29 30.011655 0.2983669 0.4882941\r\n31    30 30.819035 0.2615166 0.3964236\r\n32    31 31.626416 0.2360629 0.3094791\r\n33    32 32.433797 0.2258919 0.2330408\r\n34    33 33.241177 0.2330134 0.1809526\r\n35    34 34.048558 0.2559883 0.1763087\r\n36    35 34.855938 0.2910866 0.2221053\r\n\r\nYou will see that the equating errors are above 1 before the score of 25 as there isn’t much data in the low scores. Also, as we investigate the lower marks, we see that the gap between equated scores are increasing. For instance, 0 on form X is equal to 6.597617 on form Y. This is because there isn’t data in these regions of the scores. Despite that, equated scores get more meaningful after 20. Especially after the total score 30, the equated scores are too close and the equation error is too low, which would be quite better if the situation was like that on all total score ranges. Let’s see some other equating methods:\r\n\r\n\r\nShow code\r\n\r\n## Comparing Multiple Methods\r\n# Nominal method with mean equating\r\nQ1_nom <- equate(Q1_x, Q1_y, type = \"mean\", method = \"nom\")\r\n\r\n# Frequency method with equipercentile\r\nQ1_freq <- equate(Q1_x, Q1_y, type = \"equip\", method = \"freq\")\r\n\r\n# Braun method with linear equating\r\nQ1_braun <- equate(Q1_x, Q1_y, type = \"linear\", method = \"braun\")\r\n\r\n# Compare equated scores\r\nround(cbind(xscale = 0:35, \r\n            nominal = Q1_nom$concordance$yx,\r\n            tucker = Q1_tucker$concordance$yx, \r\n            freq = Q1_freq$concordance$yx, \r\n            braun = Q1_braun$concordance$yx), 2)\r\n\r\n      xscale nominal tucker  freq braun\r\n [1,]      0   -0.01   6.60 -0.50  5.65\r\n [2,]      1    0.99   7.40 -0.50  6.49\r\n [3,]      2    1.99   8.21 -0.50  7.32\r\n [4,]      3    2.99   9.02 -0.50  8.16\r\n [5,]      4    3.99   9.83 -0.50  9.00\r\n [6,]      5    4.99  10.63 -0.50  9.83\r\n [7,]      6    5.99  11.44 -0.50 10.67\r\n [8,]      7    6.99  12.25 -0.50 11.50\r\n [9,]      8    7.99  13.06 -0.50 12.34\r\n[10,]      9    8.99  13.86 -0.50 13.17\r\n[11,]     10    9.99  14.67 -0.50 14.01\r\n[12,]     11   10.99  15.48 -0.50 14.84\r\n[13,]     12   11.99  16.29 -0.50 15.68\r\n[14,]     13   12.99  17.09 -0.50 16.51\r\n[15,]     14   13.99  17.90 -0.50 17.35\r\n[16,]     15   14.99  18.71 -0.50 18.19\r\n[17,]     16   15.99  19.52 -0.50 19.02\r\n[18,]     17   16.99  20.32 -0.50 19.86\r\n[19,]     18   17.99  21.13 -0.50 20.69\r\n[20,]     19   18.99  21.94 -0.50 21.53\r\n[21,]     20   19.99  22.75 -0.50 22.36\r\n[22,]     21   20.99  23.55 23.66 23.20\r\n[23,]     22   21.99  24.36 23.82 24.03\r\n[24,]     23   22.99  25.17 24.10 24.87\r\n[25,]     24   23.99  25.97 24.38 25.71\r\n[26,]     25   24.99  26.78 24.57 26.54\r\n[27,]     26   25.99  27.59 25.35 27.38\r\n[28,]     27   26.99  28.40 27.28 28.21\r\n[29,]     28   27.99  29.20 29.14 29.05\r\n[30,]     29   28.99  30.01 30.65 29.88\r\n[31,]     30   29.99  30.82 31.34 30.72\r\n[32,]     31   30.99  31.63 31.76 31.55\r\n[33,]     32   31.99  32.43 32.35 32.39\r\n[34,]     33   32.99  33.24 33.09 33.22\r\n[35,]     34   33.99  34.05 33.88 34.06\r\n[36,]     35   34.99  34.86 34.86 34.90\r\n\r\nAlthough the equating methods vary, the results are similar to those of Tucker method. Especially Frequency Estimation method shows how important it is to have data in different score ranges because there is no meaningful equation before the scale score of 20 and all lower scores are equated to -.5 in this method. Let’s also see the plotting of the chart above:\r\n\r\n\r\nShow code\r\n\r\n# Plot the results\r\nplot(Q1_tucker, Q1_nom, Q1_freq, Q1_braun, lty=c(1,2,3,4),\r\n     col=c(\"blue\", \"black\", \"red\", \"forestgreen\"), addident = FALSE)\r\n\r\n\r\n\r\nAs also can be seen in the plot above, after the scale score of 20, all equating methods are quite similar to each other. Scores lower than 20 are equated with linear methods much better than the equi-percentile method as there isn’t adequate data in those score ranges.\r\nThis study is conducted for demonstrative purposes and still we can say that scale scores over 30 can be equated in the given forms.\r\n“authors”:[{“author”:“Ali Emre Karagül”,“authorURL”:“https://github.com/jimmyquidd”,\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-10-31-test-eitleme/test-eitleme_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2022-11-07T02:59:01+03:00",
    "input_file": {}
  },
  {
    "path": "posts/2022-10-31-mtk/",
    "title": "Aşama Aşama MTK Temelli Madde Analizi",
    "description": "Madde Tepki Kuramı temelli madde analizi [NOT COMPLETED YET]. Hem çok kategorili hem de iki kategorili maddeler için MTK temelli madde analizi uygulama süreçleri...",
    "author": [
      {
        "name": "Ali Emre Karagül",
        "url": "https://www.linkedin.com/in/ali-emre-karag%C3%BCl/"
      }
    ],
    "date": "2021-11-20",
    "categories": [],
    "contents": "\r\nBu çalışmada çok kategorili puanlanan maddelerden elde edilen bir veri seti kullanılmıştır. Çalışmanın ilk kısmında çok kategorili maddelere yönelik MTK analizleri yürütülmüştür. Daha sonra aynı veri seti iki kategorili verilere dönüştürülmüştür. Yine MTK süreçleri bu sefer de iki kategorili maddeler için yürütülmüştür. İzlenen adımlar şu şekildedir:\r\n1. Çoklu puanlanan maddelere yönelik olarak;\r\nUygun MTK modeli nedir?\r\nBu modele göre madde ve test parametreleri nasıldır?\r\nİdeal ve sorunlu madde örnekleri nasıldır?\r\nTest bilgi fonksiyonunu nasıldır?\r\nBirey yetenek puanlarının dağılımı nasıldır?\r\n2. Her bir maddeyi, kendi madde ortalamasından keserek 1-0 verisine dönüştürünüz. Buna göre iki kategorili puanlanan maddelere yönelik olarak;\r\nUygun MTK modeli nedir?\r\nBu modele göre madde ve test parametreleri nasıldır?\r\nİdeal ve sorunlu madde örnekleri nasıldır?\r\nTest bilgi fonksiyonunu nasıldır?\r\nBirey yetenek puanlarının dağılımı nasıldır?\r\n3. İlk iki araştırma sorusunda elde edilen birey yetenek puanları arasındaki korelasyon nasıldır?\r\n4. İlk iki araştırma sorusunda elde edilen birey yetenek puanları;\r\nÖğrencilerin fakültelerine, sınıf düzeylerine ve cinsiyetlerine göre manidar farklılık göstermekte midir?\r\nÖğrencilerin akademik ortalamaları ile manidar bir korelasyon göstermekte midir?\r\nPreprocessing\r\nTabi ki işe öncelikle verinin working directory’den yüklenmesi ve ön düzenleme süreçleri ile başladık:\r\n\r\n\r\ndata1<- read.csv2(\"sampledata.csv\")\r\nstr(data1) #yapısını incelemek için.\r\n\r\n'data.frame':   531 obs. of  25 variables:\r\n $ SIRA    : int  1 2 3 4 5 6 7 8 9 10 ...\r\n $ Fakulte : chr  \"Diger\" \"Diger\" \"Diger\" \"Diger\" ...\r\n $ Sinif   : int  4 4 5 4 5 4 4 4 4 4 ...\r\n $ Cinsiyet: chr  \"Kad\\xfdn\" \"Kad\\xfdn\" \"Kad\\xfdn\" \"Kad\\xfdn\" ...\r\n $ Ortalama: chr  \"2.88\" \"2.93\" \"3.12\" \"3.28\" ...\r\n $ L1      : int  2 1 2 2 1 3 3 1 1 2 ...\r\n $ L2      : int  1 1 4 2 1 4 4 3 4 1 ...\r\n $ L3      : int  2 4 4 3 1 4 3 1 4 4 ...\r\n $ L4      : int  1 2 4 3 2 4 4 1 2 3 ...\r\n $ L5      : int  2 4 4 4 2 5 4 1 3 4 ...\r\n $ L6      : int  1 5 4 3 4 3 3 5 4 2 ...\r\n $ L7      : int  2 1 4 3 5 4 4 1 2 3 ...\r\n $ L8      : int  1 3 3 3 1 4 4 1 2 1 ...\r\n $ L9      : int  2 1 4 4 1 3 5 1 3 4 ...\r\n $ L10     : int  1 1 2 3 2 4 4 1 4 2 ...\r\n $ L11     : int  2 1 4 3 3 4 5 4 3 2 ...\r\n $ L12     : int  1 3 4 3 5 4 5 2 3 2 ...\r\n $ L13     : int  2 1 2 2 1 2 3 1 1 4 ...\r\n $ L14     : int  1 1 1 2 1 3 4 1 2 5 ...\r\n $ L15     : int  3 3 4 3 2 3 4 1 2 4 ...\r\n $ L16     : int  1 1 1 2 1 2 2 2 2 5 ...\r\n $ L17     : int  2 2 2 2 1 3 4 1 2 4 ...\r\n $ L18     : int  2 2 2 3 4 3 2 1 2 3 ...\r\n $ L19     : int  2 2 2 3 2 4 3 1 4 2 ...\r\n $ L20     : int  1 1 2 3 1 3 4 1 3 4 ...\r\n\r\nVeri setinde ilk sütunun sıra sayıları olduğunu görünce aman tanrım dedik ve sildik.\r\n\r\n\r\ndata1<-data1[,-1] # fazla kalabalığa gerek yok, aynı isimle devam.\r\n\r\n\r\nKayıp veri olup olmadığını anlamak için:\r\n\r\n\r\ndata1[data1 == 0] <- NA\r\nsum(is.na(data1))\r\n\r\n[1] 44\r\n\r\nNeredeyse %8 oranında missing value var. Too much! Alayını atıyoruz. Artık adını da değiştirelim.\r\n\r\n\r\ndata2<- na.omit(data1)\r\n\r\n\r\nMadem ki öylesine bir veri seti ile öylesine bir analiz yapıyoruz ve practical kaygılarımız yok, veri setimizi büyütelim. 1000 kişi olsun:\r\n\r\n\r\nset.seed(16611106)  # olur da sen de denemek istersen diye aynı veri setini üretmemizi sağlar.\r\ndata3 <- data2[sample(1:495, 1000, replace = T), ] #adını da değiştirelim \r\n\r\n\r\nSon olarak, veri setinde işimize yaramayacak bir sürü demografik detay var. Atıyoruz:\r\n\r\n\r\nrow.names(data3)<- NULL #önce adlarını silelim.\r\n\r\ndata4<- data3[,5:24]  #5. sütundan sonrası çöp  \r\n\r\n\r\nÇalışmanın birinci araştırma sorusu kapsamında “data4” adlı veri seti kullanılmıştır. Bu veri seti 1000 gözlemden ve 20 değişkenden oluşmaktadır. Değişkenler, 1 ile 5 arasında bir tam sayı değeri almaktadır. Çalışmanın ikinci araştırma sorusu kapsamında ise her bir madde kendi madde ortalamasından kesilerek iki kategorili veriye dönüştürülmüştür. Bu aşamalar ilgili başlık altında raporlaştırılmıştır. Ön düzenlemelerin ardından araştırma sorularına cevap aramak için ileri analizlere devam edilmiştir.\r\n1.a. Varsayımların kontrolü ve uygun MTK modelinin belirlenmesi\r\nÇok kategorili puanlanan maddelerden oluşan ölçeğin Madde Tepki Kuramı çerçevesinde incelenmesi sürecinde öncelikle uygun MTK modelinin belirlenebilmesi için varsayım kontrolleri yapılmıştır. Bu bağlamda, tek boyutluluk ve yerel bağımsızlık varsayımları ile model-veri uyumu kontrol edilmiştir. Tek boyutluluk varsayımı kontrolü için paralel analiz, yamaç birikinti grafiği ve faktör analizi kullanılmıştır. Bu aşamada kullanılan paketler: Psych ve GPArotation.\r\nParalel Analizden elde edilen yamaç birikinti grafiği şöyledir:\r\n\r\n\r\nlibrary(psych)\r\nlibrary(GPArotation)\r\nfa.parallel(data4, n.obs = 1000, cor = \"poly\")\r\n\r\n\r\nParallel analysis suggests that the number of factors =  5  and the number of components =  2 \r\n\r\nYamaç birikinti grafiği iki bileşenli bir yapıyı göstermektedir.  Son olarak faktör analizi yardımı ile hem tek hem de iki bileşenli modeller oluşturulmuştur:\r\n\r\n\r\nfa_model1 <- fa.poly(data4)\r\nfa_model2 <- fa(data4, nfactors = 2, cor=\"poly\")\r\n\r\n\r\nBu iki modelin burada çıktılarını alsak baya uzun oluyor. Ama özetle; ben beğendiğim ve devam analizi için seçtiğim 2 faktörlü model ile devam ediyorum. Bu modelin çıktıları incelendiğinde, 1-12 numaralı maddelerin bir boyutta, 13-20 numaralı maddelerin ise diğer bir boyutta yüklendiği görülmektedir. Bu nedenle veri seti aşağıdaki adımlar izlenerek ikiye bölünmüş ve ileri analizler her iki faktör için de ayrı ayrı yürütülmüştür.\r\n\r\n\r\ndata4a<-data4[1:12]\r\ndata4b<-data4[13:20]\r\n\r\n\r\nYerel bağımsızlık varsayımının kontrolü için Yen’in Q analizi (Yen, 1984) her iki bileşen için de uygulanmıştır. Bu süreçte sirt paketinden (Robitzsch, 2020) yararlanılmış ve aşağıdaki adımlar izlenmiştir.  \r\nMod1 <- TAM::tam.mml( resp=data4a )\r\nMod1.wle <- TAM::tam.wle(Mod1)\r\nMod1.q3 <- sirt::Q3( dat=data4a, theta=Mod1.wle$theta, b=Mod1$item_irt[[3]] )\r\nMod2 <- TAM::tam.mml( resp=data4b )\r\nMod2.wle <- TAM::tam.wle(Mod2)\r\nMod2.q3 <- sirt::Q3( dat=data4b, theta=Mod2.wle$theta, b=Mod2$item_irt[[3]] )\r\nBu üstteki kodun çıktısı çooook uzun. Buraya koymuyorum. Tabi biz veriyi bootstrap ile çoğalttığımız için bu varsayım karşılanmadı ama gerçek veri ile çalışsaydık bu varsayımın karşılanmaması durumunda çöp olacaktı analiz. Yani örneklem yetersiz, daha çok örneklem lazım diyecektik. Ya da modeli veya madde sayılarını inceleyecektik vs. vs.\r\nBirinci araştırma sorusunun son aşamasında ise model veri uyumunun incelenmesi ve en uygun modelin seçilmesi yer almaktadır. Model-veri uyumu incelemesi ltm paketi (Rizopoulos, 2006) yardımı ile her iki bileşen için de ayrı ayrı GRM modeli ile yürütülmüştür. Her iki bileşende de model-1, ayırt edicilik düzeylerinin her madde için farklılaştığı modeli betimlemektedir. Model-2 ise ayırt edicilik düzeylerinin her madde için eşit tutulduğu modeldir.\r\n\r\n\r\n#install.packages(\"ltm\")\r\nlibrary(ltm)\r\nmodel1_d4a<- grm(data4a)\r\nmodel2_d4a<- grm(data4a, constrained = TRUE)\r\nmodel1_d4b<- grm(data4b)\r\nmodel2_d4b<- grm(data4b, constrained = TRUE)\r\nanova(model2_d4a, model1_d4a)\r\n\r\n\r\n Likelihood Ratio Table\r\n                AIC      BIC   log.Lik    LRT df p.value\r\nmodel2_d4a 31785.45 32025.93 -15843.72                  \r\nmodel1_d4a 31660.51 31954.98 -15770.26 146.94 11  <0.001\r\n\r\nanova(model2_d4b, model1_d4b)\r\n\r\n\r\n Likelihood Ratio Table\r\n                AIC      BIC   log.Lik   LRT df p.value\r\nmodel2_d4b 21742.58 21904.54 -10838.29                 \r\nmodel1_d4b 21664.77 21861.08 -10792.38 91.81  7  <0.001\r\n\r\nModeller arasında manidar farklılık anlamına gelen p değerlerine (<.05) sahip olmasının yanı sıra, Akaike ve Bayesian bilgi kriter değerleri en düşük olan modellerin her iki bileşen için de model-1 olduğu görülmektedir. Bu nedenle model-1 ile daha iyi bir model-veri uyumu sağlanmaktadır. Devam analizleri her iki bileşen için de model-1 ile yürütülmüştür.\r\n1.b. Madde parametreleri\r\n\r\n\r\nplot(model1_d4a, type=\"ICC\",item=6, xlab= \"YETENEK\", cex.main = 1, main = \"MADDE KARAKTERİSTİK EĞRİSİ- Madde: 6\", ylab = \"OLASILIK\" , lwd= 2, col.main= \"red\", font.axis= 3, font.lab=2)\r\n\r\n\r\nplot(model1_d4a, type=\"ICC\",xlab= \"YETENEK\", cex.main = 1, ylab = \"OLASILIK\" , lwd= 2, col.main= \"red\", font.axis= 3, font.lab=2, main = \"MADDE KARAKTERİSTİK EĞRİSİ- Madde: 2\", items = 2)\r\n\r\n\r\n\r\nTO BE CONTINUED :D\r\n\r\n\r\n\r\n",
    "preview": "posts/2022-10-31-mtk/images/mtk.png",
    "last_modified": "2022-11-07T02:58:20+03:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Greetings",
    "description": "Welcome to Ali Emre KARAGÜL's blog. I hope you enjoy \nreading it.\n\nSome of the content is in English and some in Turkish. Maybe one day they get seperated... :)",
    "author": [
      {
        "name": "Ali Emre KARAGÜL",
        "url": "https://www.linkedin.com/in/ali-emre-karag%C3%BCl/"
      }
    ],
    "date": "2021-10-31",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": "posts/welcome/images/hello.png",
    "last_modified": "2022-11-07T03:00:05+03:00",
    "input_file": {}
  }
]
